\documentclass[../notes.tex]{subfiles}

\graphicspath{{\subfix{../img/}}}

\begin{document}

\section{CSC473: Advanced Algorithms}

\subsection{Global Min-Cut}


\textbf{Given} an undirected, unweighted, and connected graph $ G = (V, E) $, \textbf{return} the smallest set of edges that disconnects $ G $



\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{img/image_2023-01-09-12-40-24.png}
  \caption{Example of global min-cut. Note that the global min-cut is not necessarily unique}
\end{figure}

\marginnote{An example of where this may be useful is in computer networks where we can measure the resiliency of a network by how many cuts must be made before a vertex (or many) get disconnected}


\begin{lemma}
  If the min cut is of size $ \ge k $, then $ G $ is $ k $-edge-connected
\end{lemma}

It may be more convenient to return a set of vertices instead

\begin{definition}
  
\begin{equation}
  S, T \subseteq V, S \cap T = \varnothing 
\end{equation}

\begin{equation}
  E(S,T) = \{(u,v) \in E : u \in S, v \in T\} 
\end{equation}

The global min-cut is to output $ S \subseteq V $ such that $ S \neq \varnothing, S \neq V $,  such that $ E(S, V\setminus S ) $ is minimized.


\end{definition}

\begin{blockquote}

Note that the min-cut-max-flow problem is somewhat of a dual to the global min-cut problem; the min-cut-max-flow problem imposes a few more constraints than the global min-cut algorithm i.e. having a directed and weighted graph as well as the notion of a source or sink.

\begin{itemize}
  \item \textbf{Input: }  Directed, weighted, and connected $ G = (V,E) $, $ s \in V, t \in V $
  \item \textbf{Output}  : $ S $ such that $ s \in S, t \notin S $ such that $  |E(S, V\setminus S ) |  $ is minimized
\end{itemize}
  
\end{blockquote}

We can kind of intuitively see that the global min-cut can be taken to the minimum of all max-flows across the graph.
So we can take the max-flow solution and then reduce it to find the global min cut.

Question: how many times will we have to run max-flow to solve the global min-cut problem? 
Naively, we may fix $ t $ to be an arbitrary node, then try every other $ s \neq t $ to find the $  s-t $ min-cut to get the best global min-cut.

We know from previous courses that the Edmonds-Karp max-flow algorithm will run in $ O(nm^2) = O(n^5) $, which makes our global min-cut algorithm $ O(n^6) $.
However, there is a paper recently published which gives an algorithm for min-cut in nearly linear time, i.e $ O(m^{1-O(1)}) = O(n^2) $  which gives a global min-cut runtime of $ O(n^3) $.

A randomized algorithm will be presented that solves this problem in $ O(n^2 \log^2 n) $


\begin{definition}
  The \textbf{Contraction} operation takes an edge $ e = (u,v) $ and \textit{contracts} it into a new node $ w $ such that all edges connected to $ u,v $ now connect to $ w $ and $ u,v $ are removed. Note that the contracted nodes can be supernodes themselves.

  \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{img/image_2023-01-12-16-47-50.png}
    \caption{Example of a series of contractions}
  \end{figure}

\end{definition}


\begin{codebox}
\Procname{$\proc{contraction}(G=(V,E))$}
\li \While $ G $ has more than 2 supernodes
\li Pick an edge $ e = (u,v) $ uniformly at random
\li Contract $ e $, remove self-loops
\li Output the cut $ (S, V \setminus S )$ corresponding to the two super nodes \End
\end{codebox}

The contraction algorithm then recurses on $ G' $, choosing an edge uniformly at random and then contracting it. 
The algorithm terminates when it reaches \textit{a} $ G' $ with only two supernodes $ v_1, v_2 $. 
The sets of nodes contracted to form each supernode $ S(v_1), S(v_2) $ form a partition of $ V $ and are the cut found by the algorithm.



\subsubsection{Analysis}

The algorithm is still random, so there's a chance that it won't find the real global min-cut. 
With some analysis we will show that the success polynomial is not exponential as one may think, but really only polynomially small.
Therefore by running the algorithm a polynomial number of times and returning the best cut identified we can find a global min-cut with high probability.


\begin{lemma}
  The contraction algorithm returns a global min cut with probability at least $ \frac{1}{\binom{n}{2}} $
  \begin{proof}
    Take a global min-cut $ (A, B) $ of $ G $ and suppose it has size $ k $, i.e. there is a set $ F $ of $ k $ edges with one end in $ A $ and the other in $ B $.
    If an edge in $ F $ gets contracted then a node of $ A$ and a node in $ B $ would get contracted together and then the algorithm would no longer output $ (A, B) $, a global min-cut.

    An upper bound on the probability that an edge in $ F $ is contracted is the ratio of $ k $ to the size of $ E $. A lower bound on the size of $ E $ can be imposed by noting that if any node $ v $ has degree $ < k $ then $ ({v}, V\setminus {v}) $ would form a cut of size less than $ k $ -- which contradicts our first assumption that $ (A,B) $ is a global min-cut.
    So the probability than an edge in $ F $ is contracted at any step is

    \begin{equation}
      \frac{k}{(\frac{k}{2})} = \frac{2}{n}
    \end{equation}

    Let's inspect the algorithm after $ j $ iterations. 
    There will be $ n-j $ supernodes in $ G' $ and we can take that no edge in $ F $ has been contracted yet. 
    Every cut of $ G' $ is a cut of $ G $, so there are at least $ k $ edges incident to every supernode of $ G' $\mn{since the min-cut has $ k $ edges}. Therefore $ G' $ has at least $ \frac{1}{2}k(n-j) $ edges, and so the probability than an edge of $ F $ is contracted in $ j+1 $ is at most

    \begin{equation}
      \frac{k}{\frac{1}{2}k(n-j)} = \frac{2}{n-j}
    \end{equation}


  The global min-cut will be actually returned by the algorithm if no edge of $ F $ is contracted in iterations $  1 - n $.
  The probability of 


  \end{proof}
  

\end{lemma}


\begin{blockquote}
  Note that there are two types of randomized algorithms:
  \begin{itemize}
    \item Monte carlo algorithms: bound on worst-case time \& produces a correct answer with a probability $ \ge  $ some constant
    \item Las vegas algorithms: bound on the expected value of running time, but the output is always correct
  \end{itemize}

  Our contraction algorithm is a monte-carlo algorithm
\end{blockquote}














\end{document}
